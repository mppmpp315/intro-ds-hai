{
 "metadata": {
  "name": "",
  "signature": "sha256:1032521ff1120b5e1e8be95d1271238af2a8556ce4d5d06b3614d27bebfe80cd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sys,os\n",
      "\n",
      "from sklearn import linear_model\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "sys.path.append('src/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import hai_data_cleanup\n",
      "reload(hai_data_cleanup)\n",
      "\n",
      "# Only 2014, 2013, and 2012 are currently avaiable (and I think they always track the previous year, but whatevs).\n",
      "data_year_files = ['data/2012/Healthcare_Associated_Infections.csv',\n",
      "                   'data/2013/Healthcare_Associated_Infections.csv', \n",
      "                   'data/2014/Healthcare Associated Infections - Hospital.csv']\n",
      "#data_years = np.arange(2005, 2014)\n",
      "data_years = np.arange(2012,2014+1).astype('str')\n",
      "\n",
      "dfs = []\n",
      "\n",
      "for year, filename in zip(data_years, data_year_files):\n",
      "    df = hai_data_cleanup.parseHAIFile(filename, year)\n",
      "    dfs.append(df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_joined = dfs[0]\n",
      "for year in range(len(data_years)):\n",
      "    df_joined = df_joined.merge(dfs[year], how='left', on=dfs[year].columns.drop('Score').tolist(), \n",
      "                                suffixes=('',' ' + data_years[year]))\n",
      "df_joined = df_joined.drop('Score',1)\n",
      "df_joined.head(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Provider ID</th>\n",
        "      <th>City</th>\n",
        "      <th>State</th>\n",
        "      <th>ZIP Code</th>\n",
        "      <th>County Name</th>\n",
        "      <th>Measure ID</th>\n",
        "      <th>Score 2012</th>\n",
        "      <th>Score 2013</th>\n",
        "      <th>Score 2014</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 30007</td>\n",
        "      <td>  COTTONWOOD</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 86326</td>\n",
        "      <td>  YAVAPAI</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 30010</td>\n",
        "      <td>      TUCSON</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85745</td>\n",
        "      <td>     PIMA</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 0.49</td>\n",
        "      <td> 0.548</td>\n",
        "      <td> 0.216</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 30011</td>\n",
        "      <td>      TUCSON</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85711</td>\n",
        "      <td>     PIMA</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 0.23</td>\n",
        "      <td> 0.077</td>\n",
        "      <td> 0.230</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 30012</td>\n",
        "      <td>    PRESCOTT</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 86301</td>\n",
        "      <td>  YAVAPAI</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 1.13</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.518</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 30013</td>\n",
        "      <td>        YUMA</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85364</td>\n",
        "      <td>     YUMA</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 0.00</td>\n",
        "      <td> 0.337</td>\n",
        "      <td> 0.449</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 30014</td>\n",
        "      <td>     PHOENIX</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85020</td>\n",
        "      <td> MARICOPA</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 1.11</td>\n",
        "      <td> 1.421</td>\n",
        "      <td> 1.101</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 30016</td>\n",
        "      <td> CASA GRANDE</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85222</td>\n",
        "      <td>    PINAL</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 0.65</td>\n",
        "      <td> 0.000</td>\n",
        "      <td> 0.384</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 30022</td>\n",
        "      <td>     PHOENIX</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85008</td>\n",
        "      <td> MARICOPA</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 1.65</td>\n",
        "      <td> 0.993</td>\n",
        "      <td> 1.365</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 30023</td>\n",
        "      <td>   FLAGSTAFF</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 86001</td>\n",
        "      <td> COCONINO</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 0.29</td>\n",
        "      <td> 0.289</td>\n",
        "      <td> 0.588</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 30024</td>\n",
        "      <td>     PHOENIX</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85013</td>\n",
        "      <td> MARICOPA</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 0.74</td>\n",
        "      <td> 0.687</td>\n",
        "      <td> 0.458</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 30030</td>\n",
        "      <td>     PHOENIX</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85015</td>\n",
        "      <td> MARICOPA</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 0.79</td>\n",
        "      <td> 0.158</td>\n",
        "      <td> 0.442</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 30033</td>\n",
        "      <td>      PAYSON</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85541</td>\n",
        "      <td>     GILA</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td>  NaN</td>\n",
        "      <td>   NaN</td>\n",
        "      <td>   NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td> 30036</td>\n",
        "      <td>    CHANDLER</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85224</td>\n",
        "      <td> MARICOPA</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 0.79</td>\n",
        "      <td> 0.184</td>\n",
        "      <td> 0.000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 30037</td>\n",
        "      <td>     PHOENIX</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85006</td>\n",
        "      <td> MARICOPA</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 1.25</td>\n",
        "      <td> 0.589</td>\n",
        "      <td> 0.521</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 30038</td>\n",
        "      <td>  SCOTTSDALE</td>\n",
        "      <td> AZ</td>\n",
        "      <td> 85251</td>\n",
        "      <td> MARICOPA</td>\n",
        "      <td> HAI_1_SIR</td>\n",
        "      <td> 0.08</td>\n",
        "      <td> 0.451</td>\n",
        "      <td> 0.649</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 182,
       "text": [
        "    Provider ID         City State  ZIP Code County Name Measure ID  \\\n",
        "0         30007   COTTONWOOD    AZ     86326     YAVAPAI  HAI_1_SIR   \n",
        "1         30010       TUCSON    AZ     85745        PIMA  HAI_1_SIR   \n",
        "2         30011       TUCSON    AZ     85711        PIMA  HAI_1_SIR   \n",
        "3         30012     PRESCOTT    AZ     86301     YAVAPAI  HAI_1_SIR   \n",
        "4         30013         YUMA    AZ     85364        YUMA  HAI_1_SIR   \n",
        "5         30014      PHOENIX    AZ     85020    MARICOPA  HAI_1_SIR   \n",
        "6         30016  CASA GRANDE    AZ     85222       PINAL  HAI_1_SIR   \n",
        "7         30022      PHOENIX    AZ     85008    MARICOPA  HAI_1_SIR   \n",
        "8         30023    FLAGSTAFF    AZ     86001    COCONINO  HAI_1_SIR   \n",
        "9         30024      PHOENIX    AZ     85013    MARICOPA  HAI_1_SIR   \n",
        "10        30030      PHOENIX    AZ     85015    MARICOPA  HAI_1_SIR   \n",
        "11        30033       PAYSON    AZ     85541        GILA  HAI_1_SIR   \n",
        "12        30036     CHANDLER    AZ     85224    MARICOPA  HAI_1_SIR   \n",
        "13        30037      PHOENIX    AZ     85006    MARICOPA  HAI_1_SIR   \n",
        "14        30038   SCOTTSDALE    AZ     85251    MARICOPA  HAI_1_SIR   \n",
        "\n",
        "    Score 2012  Score 2013  Score 2014  \n",
        "0          NaN       0.000       0.000  \n",
        "1         0.49       0.548       0.216  \n",
        "2         0.23       0.077       0.230  \n",
        "3         1.13       0.000       0.518  \n",
        "4         0.00       0.337       0.449  \n",
        "5         1.11       1.421       1.101  \n",
        "6         0.65       0.000       0.384  \n",
        "7         1.65       0.993       1.365  \n",
        "8         0.29       0.289       0.588  \n",
        "9         0.74       0.687       0.458  \n",
        "10        0.79       0.158       0.442  \n",
        "11         NaN         NaN         NaN  \n",
        "12        0.79       0.184       0.000  \n",
        "13        1.25       0.589       0.521  \n",
        "14        0.08       0.451       0.649  "
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in df_joined.columns[6:]:\n",
      "    print 'NA: ' + str(sum(pd.isnull(df_joined[col])))\n",
      "    print 'below 1 : ' + str(sum(df_joined[col] <= 1.00))\n",
      "    print 'above 1 : ' + str(sum(df_joined[col] > 1.00))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NA: 1630\n",
        "below 1 : 1987\n",
        "above 1 : 0\n",
        "NA: 1665"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "below 1 : 1952\n",
        "above 1 : 0\n",
        "NA: 1655"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "below 1 : 1962\n",
        "above 1 : 0\n"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def binByScore1(df, col):\n",
      "    #cols = df.columns[pd.Series(df.columns).str.contains('Score')]\n",
      "    def binning(score):\n",
      "        if np.isnan(score):\n",
      "            return np.nan\n",
      "        elif score > 1:\n",
      "            return -1\n",
      "        else: \n",
      "            return 1\n",
      "    df2 = df.drop(col, 1)\n",
      "    df2[col] = df[col].map(binning)\n",
      "    return df2\n",
      "\n",
      "def binByScore2(df, col, lower = -2, upper = 2):\n",
      "    #cols = df.columns[pd.Series(df.columns).str.contains('Score')]\n",
      "    def binning(z):\n",
      "            if np.isnan(z):\n",
      "                return np.nan\n",
      "            elif z > upper:\n",
      "                return -1\n",
      "            elif z < lower:\n",
      "                return 1\n",
      "            else: \n",
      "                return 0\n",
      "    mean = np.mean(df[col])\n",
      "    sd = np.std(df[col])\n",
      "    z_scores = df[col].map(lambda score: (score - mean)/sd)\n",
      "    df2 = df.drop(col, 1)\n",
      "    df2[col] = z_scores.map(binning)\n",
      "    return df2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def binByScore3(df, col, quantile = .20):\n",
      "    df = df.sort(col, ascending=False)\n",
      "    ncases = sum(df[col].notnull())\n",
      "    nmissing = sum(df[col].isnull())\n",
      "    df2 = df\n",
      "    df2[col][:quantile*ncases] = -1\n",
      "    df2[col][quantile*ncases:-(nmissing+quantile*ncases)] = 0\n",
      "    df2[col][-(nmissing+quantile*ncases):-nmissing] = 1\n",
      "    return df2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for col in df_joined.columns[6:]:\n",
      "    df2 = binByScore2(df_joined, col)\n",
      "    print 'NA: ' + str(sum(pd.isnull(df2[col])))\n",
      "    print 'better: ' + str(sum(df2[col] == 1.00))\n",
      "    print 'no different: ' +str(sum(df2[col] == 0))\n",
      "    print 'worse: ' + str(sum(df2[col] == -1.00))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "NA: 1630\n",
        "better: 0\n",
        "no different: 1894\n",
        "worse: 93"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NA: 1665\n",
        "better: 0\n",
        "no different: 1874"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "worse: 78\n",
        "NA: 1655\n",
        "better: 421\n",
        "no different: 1448"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "worse: 93\n"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_joined['Score 2012'] > 1 & df_joined['Score 2012'].notnull()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 170,
       "text": [
        "0     False\n",
        "1     False\n",
        "2     False\n",
        "3     False\n",
        "4     False\n",
        "5     False\n",
        "6     False\n",
        "7     False\n",
        "8     False\n",
        "9     False\n",
        "10    False\n",
        "11    False\n",
        "12    False\n",
        "13    False\n",
        "14    False\n",
        "...\n",
        "3602    False\n",
        "3603    False\n",
        "3604    False\n",
        "3605    False\n",
        "3606    False\n",
        "3607    False\n",
        "3608    False\n",
        "3609    False\n",
        "3610    False\n",
        "3611    False\n",
        "3612    False\n",
        "3613    False\n",
        "3614    False\n",
        "3615    False\n",
        "3616    False\n",
        "Name: Score 2012, Length: 3617, dtype: bool"
       ]
      }
     ],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(hai_data_cleanup)\n",
      "dfs_binned = []\n",
      "for year, filename in zip(data_years, data_year_files):\n",
      "    df_binned = hai_data_cleanup.parseHAIbyBinLabel(filename, year)\n",
      "    dfs_binned.append(df_binned)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(hai_data_cleanup)\n",
      "d2014 = hai_data_cleanup.parseHAIbyBinLabel('data/2014/Healthcare Associated Infections - Hospital.csv', '2014')\n",
      "d2013 = hai_data_cleanup.parseHAIbyBinLabel('data/2013/Healthcare_Associated_Infections.csv', '2013')\n",
      "d2012 = hai_data_cleanup.parseHAIbyBinLabel('data/2012/Healthcare_Associated_Infections.csv', '2012')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "values = [-1, 0, 1]\n",
      "for year in [d2014, d2013, d2012]:\n",
      "    for v in values:\n",
      "        x = np.sum(year['Compared to National'] == v)\n",
      "        print str(v) + ': ' + str(x)\n",
      "    x = np.sum(pd.isnull(year['Compared to National']))\n",
      "    print 'Nan: ' + str(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-1: 23\n",
        "0: 1401\n",
        "1: 581\n",
        "Nan: 2678\n",
        "-1: 35\n",
        "0: 1445\n",
        "1: 491\n",
        "Nan: 2696\n",
        "-1: 39\n",
        "0: 1110\n",
        "1: 489\n",
        "Nan: 1979\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_joinedBins = dfs_binned[0]\n",
      "for year in range(len(data_years)):\n",
      "    df_joinedBins = df_joinedBins.merge(dfs_binned[year], how='left', \n",
      "                                on=dfs_binned[year].columns.drop('Compared to National').tolist(), \n",
      "                                suffixes=('',' ' + data_years[year]))\n",
      "df_joinedBins = df_joinedBins.drop('Compared to National',1)\n",
      "df_joinedBins.head(15)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Provider ID</th>\n",
        "      <th>City</th>\n",
        "      <th>State</th>\n",
        "      <th>ZIP Code</th>\n",
        "      <th>County Name</th>\n",
        "      <th>Measure ID</th>\n",
        "      <th>Compared to National 2012</th>\n",
        "      <th>Compared to National 2013</th>\n",
        "      <th>Compared to National 2014</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0 </th>\n",
        "      <td> 390114</td>\n",
        "      <td>      PITTSBURGH</td>\n",
        "      <td> PA</td>\n",
        "      <td> 15213</td>\n",
        "      <td>  ALLEGHENY</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>  1</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1 </th>\n",
        "      <td> 321302</td>\n",
        "      <td>       TUCUMCARI</td>\n",
        "      <td> NM</td>\n",
        "      <td> 88401</td>\n",
        "      <td>       QUAY</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2 </th>\n",
        "      <td> 420002</td>\n",
        "      <td>       ROCK HILL</td>\n",
        "      <td> SC</td>\n",
        "      <td> 29730</td>\n",
        "      <td>       YORK</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3 </th>\n",
        "      <td> 450697</td>\n",
        "      <td>     SAN ANTONIO</td>\n",
        "      <td> TX</td>\n",
        "      <td> 78224</td>\n",
        "      <td>      BEXAR</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4 </th>\n",
        "      <td> 510007</td>\n",
        "      <td>      HUNTINGTON</td>\n",
        "      <td> WV</td>\n",
        "      <td> 25701</td>\n",
        "      <td>     CABELL</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>  0</td>\n",
        "      <td>  1</td>\n",
        "      <td>  1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5 </th>\n",
        "      <td> 260061</td>\n",
        "      <td>          NEVADA</td>\n",
        "      <td> MO</td>\n",
        "      <td> 64772</td>\n",
        "      <td>     VERNON</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6 </th>\n",
        "      <td> 450395</td>\n",
        "      <td>      LIVINGSTON</td>\n",
        "      <td> TX</td>\n",
        "      <td> 77351</td>\n",
        "      <td>       POLK</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7 </th>\n",
        "      <td> 110125</td>\n",
        "      <td>          DUBLIN</td>\n",
        "      <td> GA</td>\n",
        "      <td> 31021</td>\n",
        "      <td>    LAURENS</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8 </th>\n",
        "      <td> 420037</td>\n",
        "      <td>    SIMPSONVILLE</td>\n",
        "      <td> SC</td>\n",
        "      <td> 29681</td>\n",
        "      <td> GREENVILLE</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9 </th>\n",
        "      <td> 380038</td>\n",
        "      <td>     OREGON CITY</td>\n",
        "      <td> OR</td>\n",
        "      <td> 97045</td>\n",
        "      <td>  CLACKAMAS</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10</th>\n",
        "      <td> 521315</td>\n",
        "      <td>          BARRON</td>\n",
        "      <td> WI</td>\n",
        "      <td> 54812</td>\n",
        "      <td>     BARRON</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "      <td>NaN</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11</th>\n",
        "      <td> 310075</td>\n",
        "      <td>     LONG BRANCH</td>\n",
        "      <td> NJ</td>\n",
        "      <td>  7740</td>\n",
        "      <td>   MONMOUTH</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12</th>\n",
        "      <td>  10149</td>\n",
        "      <td>      MONTGOMERY</td>\n",
        "      <td> AL</td>\n",
        "      <td> 36117</td>\n",
        "      <td> MONTGOMERY</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13</th>\n",
        "      <td> 180011</td>\n",
        "      <td>          LONDON</td>\n",
        "      <td> KY</td>\n",
        "      <td> 40741</td>\n",
        "      <td>     LAUREL</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14</th>\n",
        "      <td> 100287</td>\n",
        "      <td> WEST PALM BEACH</td>\n",
        "      <td> FL</td>\n",
        "      <td> 33401</td>\n",
        "      <td> PALM BEACH</td>\n",
        "      <td> HAI_1_compare</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "      <td>  0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "    Provider ID             City State  ZIP Code County Name     Measure ID  \\\n",
        "0        390114       PITTSBURGH    PA     15213   ALLEGHENY  HAI_1_compare   \n",
        "1        321302        TUCUMCARI    NM     88401        QUAY  HAI_1_compare   \n",
        "2        420002        ROCK HILL    SC     29730        YORK  HAI_1_compare   \n",
        "3        450697      SAN ANTONIO    TX     78224       BEXAR  HAI_1_compare   \n",
        "4        510007       HUNTINGTON    WV     25701      CABELL  HAI_1_compare   \n",
        "5        260061           NEVADA    MO     64772      VERNON  HAI_1_compare   \n",
        "6        450395       LIVINGSTON    TX     77351        POLK  HAI_1_compare   \n",
        "7        110125           DUBLIN    GA     31021     LAURENS  HAI_1_compare   \n",
        "8        420037     SIMPSONVILLE    SC     29681  GREENVILLE  HAI_1_compare   \n",
        "9        380038      OREGON CITY    OR     97045   CLACKAMAS  HAI_1_compare   \n",
        "10       521315           BARRON    WI     54812      BARRON  HAI_1_compare   \n",
        "11       310075      LONG BRANCH    NJ      7740    MONMOUTH  HAI_1_compare   \n",
        "12        10149       MONTGOMERY    AL     36117  MONTGOMERY  HAI_1_compare   \n",
        "13       180011           LONDON    KY     40741      LAUREL  HAI_1_compare   \n",
        "14       100287  WEST PALM BEACH    FL     33401  PALM BEACH  HAI_1_compare   \n",
        "\n",
        "    Compared to National 2012  Compared to National 2013  \\\n",
        "0                           1                          0   \n",
        "1                         NaN                        NaN   \n",
        "2                           0                          0   \n",
        "3                           0                          0   \n",
        "4                           0                          1   \n",
        "5                         NaN                        NaN   \n",
        "6                         NaN                        NaN   \n",
        "7                           0                          0   \n",
        "8                         NaN                        NaN   \n",
        "9                         NaN                        NaN   \n",
        "10                        NaN                        NaN   \n",
        "11                          0                          0   \n",
        "12                          0                          0   \n",
        "13                          0                          0   \n",
        "14                          0                          0   \n",
        "\n",
        "    Compared to National 2014  \n",
        "0                           0  \n",
        "1                         NaN  \n",
        "2                           0  \n",
        "3                           0  \n",
        "4                           1  \n",
        "5                         NaN  \n",
        "6                         NaN  \n",
        "7                           0  \n",
        "8                         NaN  \n",
        "9                         NaN  \n",
        "10                        NaN  \n",
        "11                          0  \n",
        "12                          0  \n",
        "13                          0  \n",
        "14                          0  "
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfs_binned[2]['Compared to National'].value_counts()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        " 0    1401\n",
        " 1     581\n",
        "-1      23\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "values = [-1, 0, 1]\n",
      "for year in ['2014', '2013', '2012']:\n",
      "    for v in values:\n",
      "        x = np.sum(df_joinedBins['Compared to National ' + year] == v)\n",
      "        print str(v) + ': ' + str(x)\n",
      "    x = np.sum(pd.isnull(df_joinedBins['Compared to National ' + year]))\n",
      "    print 'Nan: ' + str(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-1: 23\n",
        "0: 1368\n",
        "1: 571\n",
        "Nan: 1655\n",
        "-1: 35\n",
        "0: 1430\n",
        "1: 487\n",
        "Nan: 1665\n",
        "-1: 39\n",
        "0: 1110\n",
        "1: 489\n",
        "Nan: 1979\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import data_utils\n",
      "filename = 'data/2012/Healthcare_Associated_Infections.csv'\n",
      "year_str = '2012'\n",
      "\n",
      "data = data_utils.parseFile(filename, ['Provider ID', 'City', 'State', 'ZIP Code', 'County Name', 'Measure', 'Score'])\n",
      "data = hai_data_cleanup.binByCI(data, 'CLABSI Lower Confidence Limit', 'CLABSI Upper Confidence Limit', 'Score')\n",
      "data.to_csv('2012_compare.csv')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 163
    }
   ],
   "metadata": {}
  }
 ]
}